{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Sequence Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "This week we'll look at some of the alignment algorithms discussed in lectures.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Shortcuts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find a User Guide with a description of features at http://jupyterlab.readthedocs.io\n",
    "\n",
    "The main interface we'll be using is the Jupyter Notebook interface. If you prefer to run just Jupyter Notebook itself instead of Jupyter Lab, that is fine. \n",
    "\n",
    "Some useful hotkeys are:\n",
    "\n",
    "* Shift-Enter : execute the code in the current cell\n",
    "* Enter : edit the current cell\n",
    "* ESC : stop editing a cell and return to \"command mode\" to use other hotkeys\n",
    "* m : Turn the current cell into a Markdown cell\n",
    "* y : Turn the current cell into a code cell\n",
    "* a : add a new cell above\n",
    "* b : add a new cell below\n",
    "* dd : delete the current cell\n",
    "* c : copy the current cell\n",
    "* v : paste the copied cell(s)\n",
    "\n",
    "You can also execute the command `?` or `help()` to get help on any function. For instance, `sorted?` or `help(sorted)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use numpy to create arrays and Biopython to handle DNA sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Handy function to fetch our data files\n",
    "def fetch_file(url, outpath='.'):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        print('File found!')\n",
    "        # Get the filename from the URL\n",
    "        filename = os.path.basename(url).split('?', 1)[0]\n",
    "        # Construct the filepath using the specified directory and filename\n",
    "        filepath = os.path.join(outpath, filename)\n",
    "        # Create the directory if it doesn't exist\n",
    "        if not os.path.exists(outpath):\n",
    "            print(f'Creating output dir: {outpath}')\n",
    "            os.makedirs(outpath)\n",
    "        # Check if the file already exists in the specified directory\n",
    "        if os.path.exists(filepath):\n",
    "            print(f'{filename} already exists in {outpath}. Skip download.')\n",
    "        else:\n",
    "            with open(filepath, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "                f.close()\n",
    "            print(f'Saved to: {filepath}')\n",
    "    else:\n",
    "        print(f'File not found: Code {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stylesheet\n",
    "HTML(requests.get('https://raw.githubusercontent.com/melbournebioinformatics/COMP90014/main/data/2023/style/custom.css').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch helper functions\n",
    "data = ['alignment_functions.py']\n",
    "\n",
    "for filename in data:\n",
    "    url = f'https://github.com/melbournebioinformatics/COMP90014/blob/main/data/2023/Workshop_03/src/{filename}?raw=true'\n",
    "    fetch_file(url,outpath='src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll read in some real data to play with. Nucleotide sequences for the gene incoding Insulin in mice the human homologue.\n",
    "\n",
    "We'll use nucleotide sequence rather than protein sequence, because the substitution matrix is very important when aligning protein sequences, and we won't implement substitution matrices today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch test data\n",
    "data = ['Homo_sapiens_INS_203_sequence.fa','Mus_musculus_Ins2_205_sequence.fa']\n",
    "\n",
    "for filename in data:\n",
    "    url = f'https://github.com/melbournebioinformatics/COMP90014/blob/main/data/2023/Workshop_03/data/{filename}?raw=true'\n",
    "    fetch_file(url,outpath='data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the contents of these files using the `cat` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the this file with the linux cat command\n",
    "!cat data/Homo_sapiens_INS_203_sequence.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat data/Mus_musculus_Ins2_205_sequence.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To work with these sequences in Python we will import the contents of the fasta files using the Biopython library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import with biopython as SeqRecord objects\n",
    "human_ins_record = SeqIO.read('data/Homo_sapiens_INS_203_sequence.fa', \"fasta\")\n",
    "mouse_ins_record = SeqIO.read('data/Mus_musculus_Ins2_205_sequence.fa', \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The SeqRecord contains metadata from the fasta file\n",
    "print(type(human_ins_record))\n",
    "print(human_ins_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need the sequences today so will will extract the 'seq' attribute from the SeqRecord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sequences \n",
    "human_ins = human_ins_record.seq\n",
    "mouse_ins = mouse_ins_record.seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biopython Seq objects will behave as normal strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(human_ins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Hamming distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "<b>Challange:</b> Edit the Hamming distance function below so that it returns the correct Hamming distance for two strings `a` and `b`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "E1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def hamming(s1, s2):\n",
    "    \"\"\"\n",
    "    Calculate the Hamming distance between strings a and b.\n",
    "    The strings must be the same length.\n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    '''\n",
    "    # Long form solution\n",
    "    \n",
    "    if len(s1) != len(s2):\n",
    "        print('Input strings must be equal length')\n",
    "        return\n",
    "    \n",
    "    hamming_distance = 0\n",
    "    for i in range(len(s1)):\n",
    "        if a[i] != b[i]:\n",
    "            hamming_distance += 1\n",
    "    \n",
    "    return hamming_distance\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Compact solution\n",
    "    assert len(s1) == len(s2), \"Input sequences must be same length\"\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think also: what will your function do if the strings are of different length? What *should* it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return 2\n",
    "hamming(\"GATTACA\",\"GACTATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return 6\n",
    "hamming(\"tuesday\",\"sundays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These strings are of different length!\n",
    "hamming(\"happiness\",\"applying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<div style=\"color: rgb(0,96,100); background: rgb(178,235,242); border: solid 1px rgb(77,208,225); padding: 10px;\">\n",
    "<b>Question 1:</b> Hamming distance is equal to:\n",
    "    \n",
    "A. The total number of positions at which two strings of equal length are different.\n",
    "\n",
    "B. The longest shared substring between two sequences.\n",
    "    \n",
    "C. The total number of character substitutions, insertions, or deletions required to convert one string into another.\n",
    "    </div>\n",
    "    \n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "A. The total number of positions at which two strings of equal length are different.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Levenshtein distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "<b>Challange:</b> Edit the `lev` function below to calculate Levenshtein distance recursively. You can use the costs \n",
    "* 1 for an indel\n",
    "* 1 for a mismatch\n",
    "* 0 for a match\n",
    "\n",
    "This is the same function as shown during lectures, but try to implement it without looking back at the slides.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "E2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def lev(a,b):\n",
    "    \"\"\"\n",
    "    Recursively calculate Levenshtein distance between strings a and b.\n",
    "    \"\"\"\n",
    "    if len(a)==0:\n",
    "        return len(b)\n",
    "    if len(b)==0:\n",
    "        return len(a)\n",
    "    # Add code below to calculate the distance in terms of \n",
    "    # lev(a,b[1:]), lev(a[1:],b), and lev(a[1:],b[1:])\n",
    "    # We're interested in the incremental cost of aligning the current characters,\n",
    "    # a[0] and b[0]\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    if a[0]==b[0]:\n",
    "        mismatch_cost = 0\n",
    "    else:\n",
    "        mismatch_cost = 1\n",
    "    return min( lev(a[1:],b[1:]) + mismatch_cost, # Case 1: Replace on first character\n",
    "                lev(a[1:],b) + 1, # Case 2: Remove the first character\n",
    "                lev(a,b[1:]) + 1 # Case 3: Insert first character\n",
    "               )\n",
    "\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try inserting a print statement at the top of your code to show the arguement values each time the function is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return 2\n",
    "lev(\"GATTACA\",\"GACTATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return 4\n",
    "lev(\"tuesday\",\"sundays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should return 6\n",
    "lev(\"happiness\",\"applying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<div style=\"color: rgb(0,96,100); background: rgb(178,235,242); border: solid 1px rgb(77,208,225); padding: 10px;\">\n",
    "<b>Question 2:</b> What is the time complexity class of the recursive Levenshtein Distance algorithm?\n",
    "\n",
    "\n",
    "A. Quadratic\n",
    "    \n",
    "B. Exponential\n",
    "    \n",
    "C. Linear\n",
    "    \n",
    "D. Constant\n",
    "\n",
    "</div>\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "B. Exponential\n",
    "\n",
    "=== END MARK SCHEME ===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Levenshtein distance with Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<b>Challange:</b> Find the Levenshtein Distance of two squences using a dynamic programming approach. \n",
    "\n",
    "You can use the costs:\n",
    "* 1 for an indel\n",
    "* 1 for a mismatch\n",
    "* 0 for a match\n",
    "\n",
    "- [ ] Initialise the scoregrid as a numpy array\n",
    "- [ ] Populate the first row and column with cumulative indel scores\n",
    "- [ ] Fill the matrix (starting top left to right)\n",
    "- [ ] Selecting the minimum scoring operation from {insertion, deletion, match, mismatch} at each step.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "E3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def levenshtein_distance(str1, str2):\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein distance between two strings using dynamic programming.\n",
    "\n",
    "    Parameters:\n",
    "    str1 (str): The first input string.\n",
    "    str2 (str): The second input string.\n",
    "\n",
    "    Returns:\n",
    "    int: The Levenshtein distance between the two input strings.\n",
    "    \"\"\"\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    len_str1 = len(str1)\n",
    "    len_str2 = len(str2)\n",
    "    \n",
    "    # Initialize a matrix to store distances\n",
    "    dist_matrix = np.zeros((len_str1 + 1, len_str2 + 1), dtype=int)\n",
    "    \n",
    "    # Initialize the first row and column of the matrix\n",
    "    # Note: This bit only works because our penalty score is +1\n",
    "    #       Think about how you would do this for idel penalties > 1\n",
    "    for i in range(len_str1 + 1):\n",
    "        dist_matrix[i, 0] = i\n",
    "    for j in range(len_str2 + 1):\n",
    "        dist_matrix[0, j] = j\n",
    "    \n",
    "    \n",
    "    # Fill in the rest of the matrix\n",
    "    for i in range(1, len_str1 + 1):\n",
    "        for j in range(1, len_str2 + 1):\n",
    "            if str1[i - 1] == str2[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            dist_matrix[i, j] = min(dist_matrix[i - 1, j] + 1,       # Deletion\n",
    "                                    dist_matrix[i, j - 1] + 1,       # Insertion\n",
    "                                    dist_matrix[i - 1, j - 1] + cost) # Substitution\n",
    "    \n",
    "    # The value at the bottom right corner of the matrix is the Levenshtein distance\n",
    "    levenshtein_distance = dist_matrix[len_str1, len_str2]\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return levenshtein_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function!\n",
    "str1 = \"kitten\"\n",
    "str2 = \"sitting\"\n",
    "distance = levenshtein_distance(str1, str2)\n",
    "print(f\"Levenshtein distance between '{str1}' and '{str2}': {distance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment scores, global and local alignment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function which implements a recursive alignment function like `lev()`, but returns an alignment score rather than an edit distance. Notice that it uses `max()` rather than `min()`, as we're trying to find the maximum possible score, not the minimum possible edit distance.\n",
    "\n",
    "Avoid looking at the function below until you've done Exercise 2 above as it may give away the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_recursive(a, b, indel_score=-1, match_score=2, mismatch_score=-1):\n",
    "    \"\"\"\n",
    "    Recursively calculate alignment score between strings a and b,\n",
    "    using supplied scores for matches, mismatches and indels.\n",
    "    \"\"\"\n",
    "    if len(a)==0:\n",
    "        return indel_score * len(b)\n",
    "    if len(b)==0:\n",
    "        return indel_score * len(a)\n",
    "    if a[0]==b[0]:\n",
    "        match_mismatch_score = match_score\n",
    "    else:\n",
    "        match_mismatch_score = mismatch_score\n",
    "    return max(align_recursive(a[1:],b) + indel_score,\n",
    "               align_recursive(a,b[1:]) + indel_score,\n",
    "               align_recursive(a[1:],b[1:]) + match_mismatch_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that you can now change the scoring system for indels, matches, and mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_recursive(\"GATTACA\",\"GACTATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_recursive(\"GATTACA\",\"GACTATA\",match_score=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this function is recursive and will be slow for large strings. `align_recursive(human_ins, mouse_ins)` is not practical to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global alignment: Needleman-Wunsch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do global alignment with the Needleman-Wunsch algorithm, we need two steps:\n",
    "\n",
    "1. Fill out the grid of alignment scores. This is enough to give the final alignment score.\n",
    "2. Trace-back from the bottom-right corner of the grid to get the actual alignment of the strings.\n",
    "\n",
    "Here, we've provided a function to do the traceback, and given an incomplete function to calculate the alignment score grid. Complete in the `calculate_scoregrid()` function to correctly fill out the grid of scores.\n",
    "\n",
    "For traceback, we have two options:\n",
    "* Keep track of which cell(s) was/were the origin of the best score(s) for each given cell, and use this information for traceback. This increases storage requirements by a constant factor (i.e. they are still O(N^2)).\n",
    "* Or, during traceback, calculate which cells(s) could have been the origin of the best score(s) for each cell. This increases the computational cost of traceback by a constant factor (i.e. it is still O(N)).\n",
    "\n",
    "In this case, the provided traceback function will work out which path to follow, so you don't need to keep track of the path as you calculate the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Needleman-Wunsch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "<b>Challange:</b> Complete the `calculate_scoregrid()` function to calculate the scores needed for global alignment via the Needleman-Wunsch algorithm.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "E4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# A version with scores rather than costs, which can be specified\n",
    "# Indels are scored per-base\n",
    "def calculate_scoregrid(a, b,\n",
    "                        indel_score=-1, match_score=2, mismatch_score=-1):\n",
    "    \"\"\"\n",
    "    Given two strings a and b, calculate the maximum score grid, using\n",
    "    specified scores for indels, matches and mismatches. Return the grid.\n",
    "    Grid row and column 0 correspond to \"before\" the start of each string,\n",
    "    so grid indexes are offset by 1 from string indexes. That is,\n",
    "    grid position [1,1] represents the result of matching a[0] to b[0].\n",
    "    \"\"\"\n",
    "    # The grid needs to be 1 bigger in each direction than the string lengths\n",
    "    X = len(a)+1\n",
    "    Y = len(b)+1\n",
    "    scoregrid = np.zeros((X,Y), int)\n",
    "    \n",
    "    # You need to:\n",
    "    # * initialise the top edge of grid, i.e. scoregrid[x,0] for all x, with indel scores\n",
    "    # * initialise the left edge of grid, i.e. scoregrid[0,y] for all x, with indel scores\n",
    "    # * loop over x and y, filling out each cell of the grid by looking for the\n",
    "    #   maximum possible score from each of the three earlier cells\n",
    "    \n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    # Fill out indel scores along the top and left edges\n",
    "    # It's fine to do this with two for loops instead\n",
    "    scoregrid[:,0] = list(range(0,indel_score*X,indel_score))\n",
    "    scoregrid[0,:] = list(range(0,indel_score*Y,indel_score))\n",
    "    for x in range(1,X):\n",
    "        for y in range(1,Y):\n",
    "            # Since we filled out the edges first and are working our way along each row,\n",
    "            # we can assume that the three cells contibuting to (x,y) are already filled out\n",
    "            if a[x-1]==b[y-1]: # Because our scoregrid is padded with zeros, coords are 1-indexed, whereas the sequences are 0-indexed\n",
    "                diagonal_score = match_score\n",
    "            else:\n",
    "                diagonal_score = mismatch_score\n",
    "            # Note maximum score, not minimum cost!\n",
    "            score = max(scoregrid[x-1,y] + indel_score, # Left\n",
    "                        scoregrid[x,y-1] + indel_score, # Up\n",
    "                        scoregrid[x-1,y-1] + diagonal_score # Diagonal\n",
    "                       )\n",
    "            scoregrid[x,y] = score\n",
    "            \n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return scoregrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-defined functions to get the traceback given a correct scoregrid\n",
    "# Use help(traceback) or help(get_alignment) to see how to call them\n",
    "from src.alignment_functions import traceback, get_alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `calculate_scoregrid()` works correctly, the below will work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"GATTACA\"\n",
    "b = \"GACTATA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once you've implemented calculate_scoregrid, this should show the correct\n",
    "# values instead of all zeroes\n",
    "scoregrid = calculate_scoregrid(a,b)\n",
    "scoregrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alignment score:\",scoregrid[-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the score grid isn't correct and consistent with the scoring system\n",
    "# and the strings, traceback won't be able to find a path and will give an error\n",
    "trace = traceback(a,b,scoregrid)\n",
    "aligned_string_a, aligned_string_b = get_alignment(trace)\n",
    "print(aligned_string_a)\n",
    "print(aligned_string_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try aligning the cDNA strings `human_ins` and `mouse_ins`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<div style=\"color: rgb(0,96,100); background: rgb(178,235,242); border: solid 1px rgb(77,208,225); padding: 10px;\">\n",
    "<b>Question 3:</b> Which is true of the traceback procedure for a Needleman-Wunch global-alignment matrix?\n",
    "\n",
    "A. Always moves diagonally if the current cell corresponds to the score we would get from applying a match or mismatch score to the diagonal neighbour.\n",
    "    \n",
    "B. Always selects the highest neighbouring score at each step.\n",
    "    \n",
    "C. Always selects the minimum neighbouring score to the current cell.\n",
    "    \n",
    "</div>\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "A. Always moves diagonally if the current cell corresponds to the score we would get from applying a match or mismatch score to the diagonal neighbour.\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Local Alignment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "<b>Challange:</b> Change your `calculate_scoregrid()` function to perform local instead of global alignment. You can import the `traceback_local()` function to help you test your result.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.alignment_functions import traceback_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "E5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# A version with scores rather than costs, which can be specified\n",
    "# Indels are scored per-base\n",
    "def calculate_scoregrid_local(a, b,\n",
    "                        indel_score=-1, match_score=2, mismatch_score=-1):\n",
    "    \"\"\"\n",
    "    Given two strings a and b, calculate the maximum score grid, using\n",
    "    specified scores for indels, matches and mismatches. Return the grid.\n",
    "    Grid row and column 0 correspond to \"before\" the start of each string,\n",
    "    so grid indexes are offset by 1 from string indexes. That is,\n",
    "    grid position [1,1] represents the result of matching a[0] to b[0].\n",
    "    \"\"\"\n",
    "    # The grid needs to be 1 bigger in each direction than the string lengths\n",
    "    X = len(a)+1\n",
    "    Y = len(b)+1\n",
    "    scoregrid = np.zeros((X,Y), int)\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "\n",
    "    # Fill out indel scores along the top and left edges; this will be zeros for local alignment\n",
    "    # It's fine to do this with two for loops instead\n",
    "    scoregrid[:,0] = [0] * X\n",
    "    scoregrid[0,:] = [0] * Y\n",
    "    for x in range(1,X):\n",
    "        for y in range(1,Y):\n",
    "            # Since we filled out the edges first and are working our way along each row,\n",
    "            # we can assume that the three cells contibuting to (x,y) are already filled out\n",
    "            if a[x-1]==b[y-1]:\n",
    "                diagonal_score = match_score\n",
    "            else:\n",
    "                diagonal_score = mismatch_score\n",
    "            # Note maximum score, not minimum cost!\n",
    "            # The only addition with local alignment is that the score should be > 0\n",
    "            score = max(scoregrid[x-1,y] + indel_score,\n",
    "                        scoregrid[x,y-1] + indel_score,\n",
    "                        scoregrid[x-1,y-1] + diagonal_score,\n",
    "                        0)\n",
    "            scoregrid[x,y] = score\n",
    "\n",
    "    ### END SOLUTION\n",
    "    \n",
    "    return scoregrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function\n",
    "a = 'happily'\n",
    "b = 'applying'\n",
    "\n",
    "\n",
    "scoregrid_local = calculate_scoregrid_local(a, b)\n",
    "scoregrid_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the score grid isn't correct and consistent with the scoring system\n",
    "# and the strings, traceback won't be able to find a path and will give an error\n",
    "trace = traceback_local(a,b,scoregrid_local)\n",
    "aligned_string_a, aligned_string_b = get_alignment(trace)\n",
    "print(aligned_string_a)\n",
    "print(aligned_string_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<div style=\"color: rgb(0,96,100); background: rgb(178,235,242); border: solid 1px rgb(77,208,225); padding: 10px;\">\n",
    "<b>Question 4:</b> The traceback procedure for a local-alignment matrix begins from which position?\n",
    "\n",
    "A. Smallest value\n",
    "    \n",
    "B. Top-left\n",
    "    \n",
    "C. Largest value\n",
    "    \n",
    "D. Bottom-right\n",
    "    \n",
    "</div>\n",
    "\n",
    "=== BEGIN MARK SCHEME ===\n",
    "\n",
    "C. Largest value\n",
    "\n",
    "=== END MARK SCHEME ==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
